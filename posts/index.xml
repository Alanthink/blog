<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Probability Space</title>
    <link>/blog/posts/</link>
    <description>Recent content in Posts on Probability Space</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Â©2020 Alanthink.</copyright>
    <lastBuildDate>Sat, 09 Jun 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/blog/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Multiplicative Chernoff v.s. Additive Chernoff: Which One Is Stronger?</title>
      <link>/blog/posts/2018-06-09-multiplicative-vs-additive/</link>
      <pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/2018-06-09-multiplicative-vs-additive/</guid>
      <description>Let me first show their definitions from Wikipedia 1. Note that the domain of random variables can be extended from $\{ 0, 1 \}$ to $[0, 1]$ just noting that $\E \left[ e^{tX_i} \right] \leq \E[X_i] \cdot e^t + (1 - \E[X_i])$.
Additive Chernoff bound Suppose $X_1, \dots, X_n$ are i.i.d. random variables supported on $[0, 1]$. Let $\E[X_i] = \mu$ and $\bar{X} = \frac{1}{n} \sum_{i = 1}^n X_i$. Then, we have</description>
      
    </item>
    
    <item>
      <title>Generate New Posts by Shell Scripts</title>
      <link>/blog/posts/2018-03-27-generate-new-posts-by-shell-scripts/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/2018-03-27-generate-new-posts-by-shell-scripts/</guid>
      <description>&lt;p&gt;This is the shell script I use to create a new post.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>An Application of Doob&#39;s Martingale Inequality</title>
      <link>/blog/posts/2018-03-23-doob-inequality/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/2018-03-23-doob-inequality/</guid>
      <description>Problem Suppose we have a sequence of i.i.d. Gaussian random variables $X_t$&#39;s with bounded variance. Let $S_n = \sum_{t = 1}^n X_t$. How can we bound the probability of
\begin{equation} \label{eq:problem} \left \{ \max_{1 \leq t \leq n} S_t &amp;gt; \eps \right \}? \end{equation}
Sub-gaussian random variables To make this problem more realistic, it is always safe to loose Gaussian random variables to zero mean sub-gaussian random variables.
Intuitively, sub-gaussian r.</description>
      
    </item>
    
    <item>
      <title>Test</title>
      <link>/blog/posts/2017-12-02-test/</link>
      <pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/posts/2017-12-02-test/</guid>
      <description>This is a post for testing latex formulas.
Inline formulas $e^{ix} = \cos x + i \sin x$.
Display formulas $$ \sum_{i = 1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}. $$</description>
      
    </item>
    
  </channel>
</rss>
